# Module 4: Optimizing and Monitoring Performance

- [Module 4: Optimizing and Monitoring Performance](#module-4-optimizing-and-monitoring-performance)
  - [Lab: Tuning and Monitoring Performance in a Cosmos DB Application](#lab-tuning-and-monitoring-performance-in-a-cosmos-db-application)
    - [Lab Scenario](#lab-scenario)
    - [Objectives](#objectives)
    - [Lab Setup](#lab-setup)
  - [Exercise 1: Examining Cosmos DB execution statistics](#exercise-1-examining-cosmos-db-execution-statistics)
    - [Exercise 1 Scenario](#exercise-1-scenario)
    - [Task 1: Prepare the Environment](#task-1-prepare-the-environment)
    - [Task 2: Examine the data in the collection and assess the performance of common queries](#task-2-examine-the-data-in-the-collection-and-assess-the-performance-of-common-queries)
    - [Task 3: Gather performance statistics in an application](#task-3-gather-performance-statistics-in-an-application)
  - [Exercise 2: Assessing the Impact of Consistency Levels](#exercise-2-assessing-the-impact-of-consistency-levels)
    - [Exercise 2 Scenario](#exercise-2-scenario)
    - [Task 1: Create the AddPriceHistoryToDocument trigger](#task-1-create-the-addpricehistorytodocument-trigger)
    - [Task 2: Test the trigger using different consistency levels](#task-2-test-the-trigger-using-different-consistency-levels)
    - [Task 3: Replicate the database across regions, and retest the trigger](#task-3-replicate-the-database-across-regions-and-retest-the-trigger)
  - [Exercise 3: Investigating the Effects of Triggers on Performance](#exercise-3-investigating-the-effects-of-triggers-on-performance)
    - [Exercise 3 Scenario](#exercise-3-scenario)
    - [Task 1: Implement the CreatePriceHistoryDocument trigger](#task-1-implement-the-createpricehistorydocument-trigger)
    - [Task 2: Compare the performance of using the trigger to performing the same operation in a client application](#task-2-compare-the-performance-of-using-the-trigger-to-performing-the-same-operation-in-a-client-application)
    - [Task 3: Cleanup the lab environment](#task-3-cleanup-the-lab-environment)

## Lab: Tuning and Monitoring Performance in a Cosmos DB Application

### Lab Scenario

To enable more detailed reporting, Adventure Works pricing analysts want to keep historical product price information in Cosmos DB; they will access this information through a new application. You want to investigate the impact of different document schemas, query methods, and other factors that could affect the application's performance.

### Objectives

At the end of this lab, you should be able to:

1. Gather and examine Cosmos DB execution statistics.
2. Monitor the performance of a Cosmos DB database by using the Azure portal.
3. Assess the impact of the different consistency models on a Cosmos DB application.
4. Investigate the effects of triggers on performance.

### Lab Setup

Estimated time: **60 minutes**
Virtual machine: **20777A-LON-DEV**
User name: **LON-DEV\\Administrator**
Password: **Pa55w.rd**

## Exercise 1: Examining Cosmos DB execution statistics

### Exercise 1 Scenario

To store product price history information, you have at least two options:

- Each time the price changes, create a new price history document for the product that contains the previous price together with the date in which it came into effect. The documents below show an example of this approach:

    ```JSON
    {
        "productid": "709",
        "subcategory": "Socks",
        "doctype": "Product",
        "productcategory": "Clothing",
        "productname": "Mountain Bike Socks, M",
        "productnumber": "SO-B909-M",
        "color": "White",
        "listprice": 9.5,
        "size": "M ",
        "weight": " ",
        "quantityinstock": 180,
        "model": "Mountain Bike Socks",
        "description": "Combination of natural and synthetic fibers stays dry and provides just the right cushioning.",
        "documentation": null,
        "images": null,
        "ttl": -1,
        "id": "709",
        "_rid": "TssuAK+uQZUDAAAAAAAAAA==",
        "_self": "dbs/TssuAA==/colls/TssuAK+uQZU=/docs/TssuAK+uQZUDAAAAAAAAAA==/",
        "_etag": "\"00006304-0000-0000-0000-5b7ed04c0000\"",
        "_attachments": "attachments/",
        "_ts": 1535037516
    },
    {
        "id": "709:Price:2009-02-01",
        "doctype": "ProductHistory",
        "subcategory": "Socks",
        "productid": "709",
        "listprice": "7.6000000000",
        "pricedate": "2009-02-01",
        "ttl": -1,
        "_rid": "TssuAK+uQZUEAAAAAAAAAA==",
        "_self": "dbs/TssuAA==/colls/TssuAK+uQZU=/docs/TssuAK+uQZUEAAAAAAAAAA==/",
        "_etag": "\"00006404-0000-0000-0000-5b7ed04c0000\"",
        "_attachments": "attachments/",
        "_ts": 1535037516
    },
    {
        "id": "709:Price:2009-03-01",
        "doctype": "ProductHistory",
        "subcategory": "Socks",
        "productid": "709",
        "listprice": "9.0250000000",
        "pricedate": "2009-03-01",
        "ttl": -1,
        "_rid": "TssuAK+uQZUFAAAAAAAAAA==",
        "_self": "dbs/TssuAA==/colls/TssuAK+uQZU=/docs/TssuAK+uQZUFAAAAAAAAAA==/",
        "_etag": "\"00006504-0000-0000-0000-5b7ed04c0000\"",
        "_attachments": "attachments/",
        "_ts": 1535037516
    },
    ...
    ```

- Store the price history as part of the product document:

    ```JSON
    {
        "id": "875-with-price-history",
        "productid": "875",
        "subcategory": "Socks",
        "doctype": "ProductWithPriceHistory",
        "productcategory": "Clothing",
        "productname": "Racing Socks, L",
        "productnumber": "SO-R809-L",
        "color": "White",
        "listprice": 8.99,
        "size": "L ",
        "weight": " ",
        "quantityinstock": 288,
        "model": "Racing Socks",
        "description": "Thin, lightweight and durable with cuffs that stay up.",
        "pricehistory": [
            {
                "productid": "875",
                "listprice": "10.4284000000",
                "pricedate": "2009-01-01"
            },
            {
                "ProductID": "875",
                "listprice": "8.0910000000",
                "pricedate": "2009-02-01"
            },
            {
                "ProductID": "875",
                "listprice": "9.5294000000",
                "pricedate": "2009-03-01"
            },
            {
                "ProductID": "875",
                "listprice": "8.9001000000",
                "pricedate": "2009-04-01"
            },
            ...
        ]
    }
    ```

Each approach is likely to have benefits and drawbacks. In the first case, you can end up with a lot of documents. To find the complete price history for a product could involve retrieving all of these documents. In the second case, it is easier to retrieve the full price history, but each time you fetch the details for a single product you might end up retrieving a lot of extraneous data as well.

You want to assess the possible impact of both of these strategies on your applications.

The main tasks for this exercise are as follows:

1. Prepare the environment.
2. Examine the data in the collection and assess the performance of common queries.
3. Gather performance statistics in an application.

### Task 1: Prepare the Environment

1. Ensure that the **MT17B-WS2016-NAT** and **20777A-LON-DEV** virtual machines are running, and then log on to **20777A-LON-DEV** as **LON-DEV\\Administrator** with the password **Pa55w.rd**.
2. In File Explorer, navigate to **E:\\Labfiles\\Lab04\\Starter**, right-click **full-cosmos-setup.ps1**, and then click **Edit**.
3. On line 2 of the PowerShell script, replace the text **&lt;your initials&gt;** with your initials, and replace **&lt;day&gt;** with the day of the month.
4. On line 3, change the **resourceGroupLocation** variable to reference your nearest location.
5. On the **File** menu, click **Save**.
6. On the **File** menu, click **Exit**.
7. In File Explorer, in the **E:\\Labfiles\\Lab04\\Starter** folder, right-click **Setup.cmd**, and then click **Run as administrator**.
8. When prompted enter your Azure credentials.
9. On the toolbar, click **Internet Explorer**.
10. In Internet Explorer, go to **http://portal.azure.com**, and sign in using the Microsoft account that is associated with your Azure Learning Pass subscription.
11. In the Azure portal, in the left panel, click **All resources**, and then click **20777-mod4-sql-&lt;your initials and day&gt;**.
12. On the **20777-mod7-sql-&lt;your initials and day&gt;** blade, under **Settings**, click **Keys**.
13. Make a note of the **URI**, and **PRIMARY KEY** values.

### Task 2: Examine the data in the collection and assess the performance of common queries

1. In the Azure portal, go to your Cosmos DB account, and open **Data Explorer**.
2. In the data explorer toolbar, click **Settings**, and set the **Query results per page** option to **600**.
3. Select the **Data** collection in the **Adventure-Works** database and run the following query. This query should return 4 documents; one for each type of sock that Adventure-Works sells.

    ```SQL
    SELECT * FROM c WHERE c.subcategory = "Socks" AND c.doctype = "Product"
    ```

4. Change the query as shown below and run it. This query should return 108 documents, each one showing the price of product 709 (one of the "sock" products) at some point in the past. Notice that to get the price history in sequence, you must order the data:

    ```SQL
    SELECT * FROM c WHERE c.subcategory = "Socks" AND c.doctype = "ProductHistory" AND c.productid = "709" ORDER BY c.pricedate
    ```

5. Click **Query Stats**, and make a note of the **Request Charge** showing the number of RUs required to perform this query.
6. Modify the query again, as follows, run it. This time you should see only a single document containing the product details and its full price history. Notice that the items in the **pricehistory** array are already stored in order, so you don't need to sort them as part of the query:

    ```SQL
    SELECT * FROM c WHERE c.subcategory = "Socks" AND c.doctype = "ProductWithPriceHistory" AND c.productid = "709"
    ```

7. Examine the **Query Stats** page, and compare the **Request Charge** to that of the previous query. It should be significantly lower.
8. Amend the query again and run it. This query should return the details of a single product from a **ProductWithPriceHistory** document (the price history is not included in the output).

    ```SQL
    SELECT c.productcategory, c.productname, c.productnumber, c.color, c.listprice, c.size, c.quantityinstock FROM c WHERE c.subcategory = "Socks" AND c.doctype = "ProductWithPriceHistory" AND c.productid = "709"
    ```

9. Examine the **Query Stats**, and note the **Request Charge**.
10. Change the query once more, and run it. This query should return the same data as before, but using the **Product** document instead.

    ```SQL
    SELECT c.productcategory, c.productname, c.productnumber, c.color, c.listprice, c.size, c.quantityinstock FROM c WHERE c.subcategory = "Socks" AND c.doctype = "Product" AND c.productid = "709"
    ```

11. Examine the performance figures in the **Query Stats** blade, and compare the **Request Charge** to that of the previous query. It should be less than that of the previous query. This is because the amount of I/O that Cosmos DB had to perform to fetch the document is much lower due to the document being much smaller.

### Task 3: Gather performance statistics in an application

1. On the deskstop, start Visual Studio, and open the **ProductCatalogPerformance** solution in the **E:\\Labfiles\\Lab04\\Starter\\Exercise01\\ProdoductCatalogPerformance** folder. This app enables you to perform a number of queries for product information, to test the performance of the different ways of structuring the product documents.
2. Open the **Program.cs** file.
3. Locate the **FindProductDocumentByID** method. This method retrieves a product by using the **ReadDocumentAsync** method. **ReadDocumentAsync** requires you to specify the document Uri, and the partition key for the partition containing the document. It provides the fastest access to a document in a collection.
4. In the **FindProductDocumentByID** method, under the comment **TODO write out request change and request latency**, add the following code. This code prints the request charge and time taken to the console:

    ```Csharp
    Console.WriteLine($" Request charge: {documentResponse.RequestCharge} RUs \n Request Latency: {documentResponse.RequestLatency} ms");
    ```

5. Locate the **RunAQuery** method.This method prompts the user to enter an abitrary query and then runs it (no checks are performed to ensure tha the query is valid). The query is performed with the **EnableCrossPartitionQuery** option set to true.
6. Find the **OutputProductResult** method. This method runs a specified query and displays the results.
7. In the **OutputProductResult** method, under the comment **TODO create local variables to aggregate metrics** add the following code to initialize the local variables that you will populate with performance information:

    ```CSharp
    double requestCharge = 0;
    double indexLookupTime = 0;
    double indexHitRatio = 0;
    double documentLoadTime = 0;
    double runtimeExecutionTimes = 0;
    ```
8. In the same method, under the comment **TODO aggregate metrics** add the following code to aggregate the metrics to the local variables that you set up in the previous step:

    ```Csharp
    requestCharge += queryResponse.RequestCharge;
    if (queryResponse.QueryMetrics.Count() > 0)
    {
        var queryMetrics = queryResponse.QueryMetrics.First().Value;
        indexLookupTime += queryMetrics.QueryEngineTimes.IndexLookupTime.TotalMilliseconds;
        indexHitRatio = queryMetrics.IndexHitRatio;
        documentLoadTime += queryMetrics.QueryEngineTimes.DocumentLoadTime.TotalMilliseconds;
        runtimeExecutionTimes += queryMetrics.QueryEngineTimes.RuntimeExecutionTimes.TotalTime.TotalMilliseconds;
    }
    ```

9. Under the comment **TODO Display metrics** add the following code to print the metrics to the console:

    ```Csharp
    Console.WriteLine($"\n Request charge: {requestCharge} RUs\n Index LookUp Time: {indexLookupTime} ms\n Index Hit Ratio: {indexHitRatio * 100}%\n Document Load Time: {documentLoadTime} ms\n Runtime Execution Time: {runtimeExecutionTimes} ms\n");
    ```

10. Edit the **App.config** file. In the **appSettings** section, change the value of the **EndpointUrl** and **PrimaryKey** settings to the URI and primary key for your Cosmos DB account that you recorded in task 1.
11. Build and run the application.
12. At the prompt press **A** to retrieve a document by id/subcategory using the **ReadDocumentAsync** method. Specify product id **709** and partition key **Socks** when prompted. Note the value of the request charge for the query.
13. To compare the effect of embedding the price history information in the product documents with holding the price history in individual documents on queries that read product information, at the prompt press **R** to invoke the **RunAQuery** method, and then enter the following query:

    ```SQL
    SELECT c.id, c.productcategory, c.productname, c.productnumber, c.listprice FROM c where c.doctype = 'Product'
    ```
14. Note the metrics.
15. At the prompt, press **R** again, and then enter the following query:

    ```SQL
    SELECT c.id, c.productcategory, c.productname, c.productnumber, c.listprice FROM c where c.doctype = 'ProductWithPriceHistory'
    ```

16. Compare the metrics from both queries. Observe that the larger documents (the second query) have a higher RU cost to return the same information (~20-25%). The Document Load Time has more than doubled.

    **Question**: What conclusions do you draw from these results?

17. To compare the performance of retrieving price history information, at the prompt, press **R**, and then run the following query:

    ```SQL
    select c.productid, c.listprice, c.pricedate from c where c.doctype = 'ProductHistory'
    ```

18. Note the metrics.
19. Press **R**, and run the following query:

    ```SQL
    SELECT x.productid, x.listprice, x.pricedate FROM c JOIN x IN c.pricehistory where c.doctype = 'ProductWithPriceHistory'
    ```

20. Compare the metrics from both queries. Observe that the RU cost of the second query is ~30% lower. The Document Load Time and Runtime Execution Time are also significantly lower.

    **Question**: What conclusions do you draw from these results? What changes might you implement to improve the performance of retrieving price history data?

21. Press **X** to exit the application.
22. In Visual Studio, in the Program.cs  file, find the **CreateProductHistories** method. This method is not currently implemented. Replace the existing statement in this method with the following code. This code creates seperate product history documents from the prices recorded in the price history array of the **ProductWithPriceHistory** documents.

    ```CSharp
    private async Task CreateProductHistories()
    {
        SqlQuerySpec querySpec = new SqlQuerySpec()
        {
            QueryText = "SELECT * FROM c WHERE c.doctype = 'ProductWithPriceHistory'"
        };

        FeedOptions queryOptions = new FeedOptions { MaxItemCount = -1, EnableCrossPartitionQuery = true, PopulateQueryMetrics = this.enableLogging };
        var productWithHistoryQuery = client.CreateDocumentQuery<ProductWithHistory>(UriFactory.CreateDocumentCollectionUri(this.database, this.collection), querySpec, queryOptions).AsDocumentQuery();

        while (productWithHistoryQuery.HasMoreResults)
        {
            var queryResponse = (productWithHistoryQuery.ExecuteNextAsync()).Result;
            foreach (var queryDoc in queryResponse)
            {
                dynamic productHistories = new System.Dynamic.ExpandoObject();
                productHistories.productid = queryDoc.productid;
                productHistories.pricehistory = queryDoc.pricehistory;
                productHistories.doctype = "ProductHistories";
                productHistories.subcategory = queryDoc.subcategory;

                var createResponse = await client.CreateDocumentAsync(UriFactory.CreateDocumentCollectionUri(this.database, this.collection), productHistories);
            }
        }
    }
    ```

23. Build and run the application.
24. At the prompt press **D** to create the **ProductHistories** records for each product in the collection. This operation will take a little time.
25. To compare the performance of retrieving price history information, at the prompt, press **H** to prevent results being displayed, and then press **R**.
26. Run the following query:

    ```SQL
    SELECT x.productid, x.listprice, x.pricedate FROM c JOIN x IN c.pricehistory WHERE c.doctype = 'ProductHistories'
    ```

27. Compare the metrics with the product history query metrics that you recorded earlier in the exercise. Notice that the **ProductHistories** query has similar metrics to the **ProductWithPriceHistory** query. This approach gives you good performance for both price history and standard product catalog queries.
28. Press **X** to close the app, and then close Visual Studio.

## Exercise 2: Assessing the Impact of Consistency Levels

### Exercise 2 Scenario

As part of the investigations on the optimal manner to store and maintain product price histories, you decide to investigate the **ProductWithPriceHistory** model a little further. Remember that documents using this model look like this:

```JSON
{
    "id": "875-with-price-history",
    "productid": "875",
    "subcategory": "Socks",
    "doctype": "ProductWithPriceHistory",
    "productcategory": "Clothing",
    "productname": "Racing Socks, L",
    "productnumber": "SO-R809-L",
    "color": "White",
    "listprice": 8.99,
    "size": "L ",
    "weight": " ",
    "quantityinstock": 288,
    "model": "Racing Socks",
    "description": "Thin, lightweight and durable with cuffs that stay up.",
    "pricehistory": [
        {
            "productid": "875",
            "listprice": "10.4284000000",
            "pricedate": "2009-01-01"
        },
        {
            "ProductID": "875",
            "listprice": "8.0910000000",
            "pricedate": "2009-02-01"
        },
        {
            "ProductID": "875",
            "listprice": "9.5294000000",
            "pricedate": "2009-03-01"
        },
        {
            "ProductID": "875",
            "listprice": "8.9001000000",
            "pricedate": "2009-04-01"
        },
        ...
    ]
}
```

You decide to use a **Pre** trigger that runs every time the price in a **ProductWithPriceHistory** document is updated. This trigger captures the current price (before the change), and creates and appends the appropriate sub-document to the **pricehistory** field. You want to verify that this approach will work as expected across the different consistency models that might be required by applications using the database.

The main tasks for this exercise are as follows:

1. Create the **AddPriceHistoryToDocument** trigger.
2. Test the trigger using different consistency levels.
3. Replicate the database across regions, and retest the trigger.

### Task 1: Create the AddPriceHistoryToDocument trigger

> **Note:** The JavaScript code used in this task can be found in the file **E:\\Labfiles\\Lab04\\\Solution\\Exercise02\\AddPriceHistoryToDocument.txt**.

1. In the Azure portal, make a note of the **URI** and **PRIMARY KEY** for your Cosmos DB account.
2. On the desktop, using File Explorer, navigate to **E:\\Labfiles\\Lab04\\Starter**, right-click **create-database-partitioned-by-productid.ps1**, and then click **Edit**.
3. In PowerShell ISE, on line 2, replace the text **~URI~** with the URI of your Cosmos DB account.
4. On line 3, change the text **~KEY~** to the primary key of your Cosmos DB account.
5. On the **File** menu, click **Save**.
6. Examine the script; it creates another collection, called **Data2**, that holds product catalog information. This time the data is partitioned by the **productid** field
7. On the **File** menu, click **Run**.
8. Wait for the script to complete. It should upload 34344 documents to the collection.
9. Close PowerShell ISE.
10. In the Azure portal, go to your Cosmos DB account in the Azure portal.
11. Open **Data Explorer**, and select the **Data2** collection in the **Adventure-Works** database. This is the collection that is partitioned by product id.
12. Add a new trigger named **AddPriceHistoryToDocument** to the collection. Leave the **Trigger Type** set to **Pre**, and the **Trigger Operation** set to **All**.
13. Add the following code to the trigger, and then save it:

    ```JavaScript
    function trigger(){
        var context = getContext();  
        var request = context.getRequest();
        var collection = context.getCollection();  
        var documentBeingUpdated = request.getBody();

        // If the operation being performed is not an upsert, then ignore this trigger
        if (request.getOperationType() != "Upsert") {
            return;
        }

        // Verify the type of the document - should be a ProductWithPriceHistory
        if (!("doctype" in documentBeingUpdated) && documentBeingUpdated.doctype != "ProductWithPriceHistory") {
            throw new Error("Wrong type of document");
        }

        // Create a pricehistory subdocument using the data from the document triggering the operation
        var newPriceHistorySubDoc =
        {
            productid: documentBeingUpdated.productid,
            listprice: documentBeingUpdated.listprice,
            pricedate: new Date().toISOString().slice(0,10)
        };

        // Add the pricehistory subdocument to start of the pricehistory array
        documentBeingUpdated.pricehistory.push(newPriceHistorySubDoc);

        // Save the changes
        request.setBody(documentBeingUpdated);
    }
    ```

### Task 2: Test the trigger using different consistency levels

1. Using the Azure portal, examin the default consistency model used by the Cosmos DB account; it should be **BOUNDED STALENESS**. Applications can override this consistency level to lower it, but canot increase it to **STRONG**.
2. On the deskstop, start Visual Studio, and open the **PriceChangeTester** solution in the **E:\\Labfiles\\Lab04\\Starter\\Exercise02\\PriceChangeTester** folder.
3. Edit the **Program.cs** file and locate the **DoWork** method in the **Worker** class. This method connects to the database, reads the document for a specified product, changes the price (it adds 0.5), and then saves it back to the collection, firing the **AddPriceHistoryToDocument** trigger as it does so. Note that the update is protected by using the **ETag** to prevent any concurrent changes from being lost, as follows. If a concurrent change is detected, the app throws an exception which is caught and reported by the handler at the end of the method:

    ```CSharp
    // Save the doc back to the collection
    options = new RequestOptions
    {
        AccessCondition = new AccessCondition
        {
            Condition = document.ETag,
            Type = AccessConditionType.IfMatch
        },
        PreTriggerInclude = new List<string>{ "AddPriceHistoryToDocument" }
    };

    var updateResponse = await client.UpsertDocumentAsync(
        UriFactory.CreateDocumentCollectionUri(this.database, this.collection), document, options);
    Console.WriteLine("Document updated");
    ```

4. Scroll up to the **Main** method of the **Program** class. This method prompts the user for a product id, and then runs the **DoWork** method of a **Worker** object 100 times in quick succession. These runs are all performed sequentially rather than concurrently; only one update to the specified product document should occur at a time:

    ```CSharp
    static void Main(string[] args)
    {
        Console.WriteLine("Enter product ID");
        string id = Console.ReadLine();

        Worker worker = new Worker();
        for (int i = 0; i < 100; i++)
        {
            worker.DoWork(id).Wait();
        }

        Console.WriteLine("Press Enter to finish");
        Console.ReadLine();
    }
    ```

5. Edit the **App.config** file, and add the URI and primary ket to the **appSettings** section where indicated.
6. Build and run the application.
7. At the **Enter product ID** prompt, enter 717. This will cause the price of product 717 to be updated. The app displays the complete document each time it is updated, and you should see the new price being appended to the array at the end of the document.
8. Verify that the app runs without reporting any exceptions, and then press Enter to close it.
9. Return to Vsual Studio.
10. In the **Program.cs** file, in the **DoWork** method, locate the following statement. This code creates the client object that connects to the database, notice that it specified a consistency level of **BoundedStaleness**:

    ```CSharp
    // Connect to the Cosmos DB account
    this.client = new DocumentClient(new Uri(endpointUrl), primaryKey, null, ConsistencyLevel.BoundedStaleness);
    ```

11. Change the consistency level to **ConsistencyLevel.Eventual**.
12. Build and run the application again.
13. At the **Enter product ID** prompt, enter 718.
14. Verify that the app operates as before, except that it is modifying the price of a different product.
15. Verify that the app runs without reporting any exceptions, and then press Enter to close it.
16. Return to Vsual Studio.
17. Repeat steps 10 to 16, using the following consistency levels. In each case, the app should run successfully:
    - **ConsistencyLevel.Session**
    - **ConsistencyLevel.ConsistentPrefix**
  
### Task 3: Replicate the database across regions, and retest the trigger

1. In the Azure portal, on the blade displaying the default consistency for your Cosmos DB account, verify that it is still set to **BOUNDED STALENESS**.
2. Change the **Maximum Lag(Time)** to 5 minutes, the **Maximum Lag(Operations)** to **100000**, and save the changes.

   > **Note:** These changes are necessary as they are the minimum values supported by the bounded staleness consistency level when you replicate data across regions.

3. Under **Settings**, click **Replicate data globally**.
4. On the **Replicate data globally** blade, click a location that is physically distant from your write region. For example, if your write region is **Central US**, click **Southeast Asia**.
5. Save the configuration and wait while the replication is configured. This can take several minutes.
6. Return to Visual Studio.
7. In the **Program.cs** file, in the **DoWork** method, change the consistency level used by the application back to **BoundedStaleness** as follows:

    ``` CSharp
    // Connect to the Cosmos DB account
    this.client = new DocumentClient(new Uri(endpointUrl), primaryKey, null, ConsistencyLevel.BoundedStaleness);
    ```

8. Build and run the application.
9. At the **Enter product ID** prompt, enter 725.
10. Verify that the app runs without reporting any exceptions, and then press Enter to close it.
11. Return to Vsual Studio.
12. In the **Program.cs** file, in the **DoWork** method, change the consistency level used by the application back to **Eventual** as follows:

    ``` CSharp
    // Connect to the Cosmos DB account
    this.client = new DocumentClient(new Uri(endpointUrl), primaryKey, null, ConsistencyLevel.Eventual);
    ```

13. Build and run the application again.
14. At the **Enter product ID** prompt, enter 726. The application will start updating documents, but at some point will throw the following exception.

    ```Text
    Message: {"Errors":["One of the specified pre-condition is not met"]}
    ActivityId: 5e601622-0365-4bc0-a6c7-62c47c2ae7c1, Request URI: /apps/3666e0f0-ed7d-4e2e-8558-f69907b4ff5d/services/6e89fcb4-cbba-4b28-81b0-4714995eb1e6/partitions/0b3a4866-d542-4610-b3f3-c814312956c0/replicas/131798616051453023p, RequestStats:
    RequestStartTime: 2018-08-29T10:56:36.7260805Z, Number of regions attempted: 0
    , SDK: Microsoft.Azure.Documents.Common/2.0.0.0, Windows/10.0.17134 documentdb-netcore-sdk/1.9.1
    ```

    This exception occurs when the ETag for a document being updated is different from that expected. This situation typically occurs when two users are attempting to update the same document at the same time, and the solution for the app is to read the document again to retrieve the latest version of the document containing the latest ETag, update it, and store it back in the database (this is the optimistic concurrent approach). But in this case, there is only one user, and that user is performing updates serially. The problem is caused by the replication configuration. When the client app updates a document, not all copies of that document across all nodes are changed immediately. This is performance reasons. The changes will *eventually* be propagated. If the app is using the bounded staleness consistency level this is not a problem and the app will be presented with the most recent version of a document (within a given timeframe). However, this takes a little time as the system has to ascertain what the latest version actually is. The eventual consistency model simply fetches any copy of the document regardless of its version, and this might not be the latest version. If the app is presented with an outdated version of the document, modifies it, and then writes it back to the database, it could lose one or more changes. Using the ETag to check the version of the document prevents this from occurring. Note that this is not an issue with using triggers, rather it is a feature of any system that implements eventual consistency
15. Press Enter and allow the app to continue. It will likely trigger more exceptions as the same problem recurs.
16. When the app has finished, press Enter to close the app, and then close Visual Studio.

## Exercise 3: Investigating the Effects of Triggers on Performance

### Exercise 3 Scenario

You now decide to investigate the efficiency of storing product price history information as a series of seperate documents as an alternative to using an array of prices stored with the product itself. Each time the price of a product changes, a new **PriceHistory** document  should be created that looks similar to this:

```JSON
{
    "id": "737:Price:2009-01-01",
    "doctype": "ProductHistory",
    "subcategory": "Road Frames",
    "productid": "737",
    "listprice": "269.7760000000",
    "pricedate": "2009-01-01",
    ...
}
```

You want to determine whether to use a **Pre** trigger that creates a new **ProductHistory** document every time the price in a **Product** document changes, or whether it is more efficient to perform this task explicitly in a client application.

The main tasks for this exercise are as follows:

1. Implement the **CreatePriceHistoryDocument** trigger.
2. Compare the performance of using the trigger to performing the same operation in a client application.
3. Cleanup the lab environment.

### Task 1: Implement the CreatePriceHistoryDocument trigger

> **Note:** The JavaScript code used in this task can be found in the file **E:\\Labfiles\\Lab04\\\Solution\\Exercise03\\CreatePriceHistoryDocument.txt**.

1. In the Azure portal, go to your Cosmos DB account, and use **Data Explorer** to navigate to the **Data2** collection in the **Adventure-Works** database
2. Create a new trigger named enter **CreatePriceHistoryDocument**. Leave the **Trigger Type** set to **Pre**, and the **Trigger Operation** set to **All**.
3. Change the code in the **Trigger Body** box as shown below:

    ```JavaScript
    function trigger(){
        var context = getContext();  
        var request = context.getRequest();
        var collection = context.getCollection();  
        var documentBeingUpdated = request.getBody();

        // If the operation being performed is not an upsert, then ignore this trigger
        if (request.getOperationType() != "Upsert") {
            return;
        }

        // Verify the type of the document - should be a Product
        if (!("doctype" in documentBeingUpdated) && documentBeingUpdated.doctype != "Product") {
            throw new Error("Wrong type of document");
        }

        // Create a ProductHistory document using the data from the document triggering the operation
        var priceDate = new Date().toISOString();
        var priceHistoryDoc =
        {
            id: documentBeingUpdated.productid + ":Price:" + priceDate,
            doctype: "ProductHistory",
            subcategory: documentBeingUpdated.subcategory,
            productid: documentBeingUpdated.productid,
            listprice: documentBeingUpdated.listprice,
            pricedate: priceDate
        }

        // Attempt to save the ProductHistory document
        var isAccepted = collection.createDocument(collection.getSelfLink(), priceHistoryDoc);

        // If the trigger is out of runtime, throw an error
        if (!isAccepted) {
            throw new Error('Unable to create price history document');
        }
    }
    ```

    > **Note:** For this exercise, the date is stored as a full ISO string, including the time down to the nearest milliscond. Previously, the document only stored the day, month, and year because it was assumed that a product would not change price more than once in a day. In this exercise, you are going to be performing a number of updates in quick succession, so just using the date without the time would result in multiple documents attempting to use the same document ID.

4. Save the trigger.

### Task 2: Compare the performance of using the trigger to performing the same operation in a client application

1. Start Visual Studio, and open the **PriceChangePerformanceTester** solution in the **E:\\Labfiles\\Lab04\\Starter\\Exercise03\\PriceChangePerformanceTester** folder.
2. Open the **Program.cs** file.
3. Locate the **DoWork** method in the **Worker** class. This method is very similar to that used by the **PriceChangeTester** app in exercise 3. The primary differences are that it takes an additional boolean parameter, **useTrigger**, that indicates whether the method should create the **ProductHIstory** document using the trigger you just created, or whether this task should be performed by the client.
4. Scroll down to the comment **Save the document back to the collection** and examine the code at this point:

    ```CSharp
    // Save the doc back to the collection
    double result = 0.0;
    if (useTrigger)
    {
        result = await SaveDocumentUsingTrigger(document);
    }
    else
    {
        result = await SaveDocumentWithoutUsingTrigger(document);
    }
    return result;
    ```

    This code calls either the **SaveDocumentUsingTrigger** or **SaveDocumentWithoutUsingTrigger** method, depending on the value of **useTrigger**.

5. Find the **SaveDocumentUsingTrigger** method. It looks like this:

    ```CSharp
    // Save the document using the trigger to add the price change history document
    // Return the request charge
    private async Task<double> SaveDocumentUsingTrigger(Document document)
    {
        var options = new RequestOptions
        {
            AccessCondition = new AccessCondition
            {
                Condition = document.ETag,
                Type = AccessConditionType.IfMatch
            },
            PreTriggerInclude = new List<string> { "CreatePriceHistoryDocument" }
        };

        var updateResponse = await client.UpsertDocumentAsync(
            UriFactory.CreateDocumentCollectionUri(this.database, this.collection), document, options);
        Console.WriteLine("Document updated using trigger");
        return updateResponse.RequestCharge;
    }
    ```

    This code is very similar to that used in the previous exercise, except that it runs the **CreatePriceHistoryDocument** trigger, and returns the request charge for performing this operation.

6. Find the **SaveDocumentWithoutUsingTrigger** method:

    ```CSharp
    // Save the document without using the trigger
    // Create and save the price change history document manually
    // Return the request charge
    private async Task<double> SaveDocumentWithoutUsingTrigger(Document document)
    {
        var options = new RequestOptions
        {
            AccessCondition = new AccessCondition
            {
                Condition = document.ETag,
                Type = AccessConditionType.IfMatch
            }
        };

        var updateResponse = await client.UpsertDocumentAsync(
            UriFactory.CreateDocumentCollectionUri(this.database, this.collection), document, options);
        Console.WriteLine("Document updated without using trigger");

        var historyDocument = new Document();
        var priceDate = DateTime.Now.ToString("yyyy-MM-dd HH:mm:ss.fffffff");
        var productID = document.GetPropertyValue<string>("productid");
        historyDocument.SetPropertyValue("id", $"{productID}:Price:{priceDate}");
        historyDocument.SetPropertyValue("doctype", "ProductHistory");
        historyDocument.SetPropertyValue("subcategory", document.GetPropertyValue<string>("subcategory"));
        historyDocument.SetPropertyValue("productid", productID);
        historyDocument.SetPropertyValue("listprice", document.GetPropertyValue<string>("listprice"));
        historyDocument.SetPropertyValue("pricedate", priceDate);

        var insertResponse = await client.CreateDocumentAsync(
            UriFactory.CreateDocumentCollectionUri(this.database, this.collection), historyDocument);
        Console.WriteLine("History document added");

        return updateResponse.RequestCharge + insertResponse.RequestCharge;
    }
    ```

    This code saves the **Product** document without firing the trigger. It then creates a **ProductHistory** document and inserts it into the database. The request charge for both operations is aggregated and returned.

7. Scroll up to the **Main** method of the **Program** class. This method prompts the user for a product id, and then iterates 100 times run the **DoWork** method both with and without invoking the trigger. The request charges are accumulated and displayed when the application completes. These figures should give you a comparison of the costs involved for performing the update using the trigger and by using code:

    ```CSharp
    static void Main(string[] args)
    {
        Console.WriteLine("Enter product ID");
        string id = Console.ReadLine();

        double requestChargeUsingTrigger = 0.0;
        double requestChargeWithoutUsingTrigger = 0.0;

        Worker worker = new Worker();
        for (int i = 0; i < 100; i++)
        {
            requestChargeUsingTrigger = worker.DoWork(id, true).Result;         // Use the trigger and get the response including the performance metrics
            requestChargeWithoutUsingTrigger = worker.DoWork(id, false).Result; // Don't use the trigger
        }

        Console.WriteLine($"Total request charge using trigger: {requestChargeUsingTrigger} RUs");
        Console.WriteLine($"Total request charge without using trigger: {requestChargeWithoutUsingTrigger} RUs");
        Console.WriteLine("Press Enter to finish");
        Console.ReadLine();
    }
    ```

8. Edit the **App.config** file, and add the URI and primary key of your Cosmos DB account where indicated in the **appSettings** section.
9. Build and run the application.
10. At the **Enter product ID** prompt, enter 730. This will update the price of product 740 200 times; 100 times using the trigger and 100 times using client code
11. When the app finishes note the request charges with and without using the trigger, and then press Enter to close it.
12. Run the app several more times, using products 731, 732, and 733. Each time note the request charges when the app completes.

    **Question**: What do you notice about the request charges for each run of the app?

13. Close the app, and then close Visual Studio.

### Task 3: Cleanup the lab environment

1. In Internet Explorer, in the left panel, click **Resource groups**.
2. In the **Resource groups** blade, right-click **20777Mod04**, and then click **Delete resource group**.
3. In the **Are you sure you want to delete "20777Mod04"?** blade, in the **TYPE THE RESOURCE GROUP NAME** box, type **20777Mod04**, and then click **Delete**.

---

© 2019 Microsoft Corporation. All rights reserved.

The text in this document is available under the [Creative Commons Attribution 3.0 License](https://creativecommons.org/licenses/by/3.0/legalcode), additional terms may apply. All other content contained in this document (including, without limitation, trademarks, logos, images, etc.) are **not** included within the Creative Commons license grant. This document does not provide you with any legal rights to any intellectual property in any Microsoft product. You may copy and use this document for your internal, reference purposes.

This document is provided "as-is." Information and views expressed in this document, including URL and other Internet Web site references, may change without notice. You bear the risk of using it. Some examples are for illustration only and are fictitious. No real association is intended or inferred. Microsoft makes no warranties, express or implied, with respect to the information provided here.
